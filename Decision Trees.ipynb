{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import copy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code creates a Decision Tree on the Abalone dataset from the UCI Machine Learning Repository https://archive.ics.uci.edu/ml/index.php\n",
    "\n",
    "[Datasets](#Datasets):   \n",
    "[Abalone](#Abalone)  \n",
    "\n",
    "Algorithms-  \n",
    "[Decision Tree ID3](#Decision_Tree)  \n",
    "[Reduced Error Pruning](#Pruning)  \n",
    "\n",
    "[Processing](#Processing) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Datasets\"></a>\n",
    "# Datasets\n",
    "\n",
    "<a id=\"Abalone\"></a>\n",
    "## Abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone = pd.read_csv( \"abalone.data\", header = None,  names = ['sex','length','diameter','height','whole_weight','shucked_weight','viscera_weight','shell_weight','rings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex  length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   shell_weight  rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "<a id=\"Decision_Tree\"></a>\n",
    "## Decision Tree- ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to create a decision tree and test it on a set of test data\n",
    "# data is the dataset to be used for the algorithm\n",
    "# test is a list of indices from data to be used for testing\n",
    "# validation is a list of indices from data to be used for validation\n",
    "# train is a list of indices from data to be used for training\n",
    "# features is a list of the indicies for the features to be used to measure distance\n",
    "# target_class is the index of the target class feature\n",
    "# returns a list of classes, the indices which correspond to the indices of test\n",
    "def test_id3(data, test, validation, train, features, target_class, target_type):\n",
    "    # get id3 tree\n",
    "    root = id3(data, test, validation, train, features, target_class, None, None, target_type, None)\n",
    "    # use tree to get classes for test dataset\n",
    "    test_classes = []\n",
    "    for index in range(len(test)):\n",
    "        # get record\n",
    "        node = root\n",
    "        node_feature = node.split_feature # index of feature in data being tested for\n",
    "        record = data.iloc[[test[index]]]\n",
    "        check = 0\n",
    "        record_class = -1\n",
    "        while(check == 0):\n",
    "            if(node.is_leaf == True):\n",
    "                record_class = node.leaf_class\n",
    "                check = 1\n",
    "            # end if\n",
    "            if(node_feature == None):\n",
    "                record_class = node.leaf_class\n",
    "                check = 1\n",
    "            # end if\n",
    "            # node is not leaf, move to next level\n",
    "            # cycle through child nodes until find the one we want\n",
    "            if(check == 0):\n",
    "                child_nodes = node.children\n",
    "                check2 = 0\n",
    "                while(check2 == 0):\n",
    "                    for child_node_index in range(len(child_nodes)):\n",
    "                        child_node = child_nodes[child_node_index]\n",
    "                        # check if node is split on an object feature\n",
    "                        colname = data.columns[node_feature]\n",
    "                        if(child_node.feature_quality == None or data[colname].dtype == 'O'):\n",
    "                            if(child_node.feature_element == record.iloc[0,node_feature]):\n",
    "                                # this is our child node, update accordingly\n",
    "                                node = child_node\n",
    "                                check2 = 1\n",
    "                                if(child_node.split_feature == None):\n",
    "                                    node_feature = target_class\n",
    "                                # end if\n",
    "                                else:\n",
    "                                    node_feature = child_node.split_feature\n",
    "                                # end else  \n",
    "                            # end if  \n",
    "                        # end if\n",
    "                        else:\n",
    "                            if(child_node.feature_quality > 0 and record.iloc[0,node_feature] >= child_node.feature_element): \n",
    "                                # this is our child node, update accordingly\n",
    "                                node = child_node\n",
    "                                if(child_node.split_feature == None):\n",
    "                                    node_feature = target_class\n",
    "                                # end if\n",
    "                                else:\n",
    "                                    node_feature = child_node.split_feature\n",
    "                                # end else\n",
    "                                check2 = 1\n",
    "                            # end if  \n",
    "                            else:\n",
    "                                if(child_node.feature_quality < 0 and record.iloc[0,node_feature] < child_node.feature_element):\n",
    "                                    # this is our child node, update accordingly\n",
    "                                    node = child_node\n",
    "                                    if(child_node.split_feature == None):\n",
    "                                        node_feature = target_class\n",
    "                                    # end if\n",
    "                                    else:\n",
    "                                        node_feature = child_node.split_feature\n",
    "                                    # end else\n",
    "                                    check2 = 1\n",
    "                                # end if\n",
    "                            # end else\n",
    "                        # end else\n",
    "                        \n",
    "                    # end for\n",
    "                    if(check2 == 0): # cycled through all child nodes, none of the features matched, return class of node\n",
    "                        record_class = node.leaf_class\n",
    "                        check2 = 1\n",
    "                        check = 1\n",
    "                    # end if\n",
    "                # end while               \n",
    "            # end if\n",
    "        # end while\n",
    "        test_classes.append(record_class)\n",
    "    #end for\n",
    "\n",
    "    #for index in range(len(test)):\n",
    "        #print(\"test class guess:\")\n",
    "        #print(test_classes[index])\n",
    "        #print(\"actual:\")\n",
    "        #record = data.iloc[[test[index]]]\n",
    "        #print(record.iloc[0,target_class])\n",
    "    return test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID3 Decision Tree method\n",
    "# data is the dataset to be used for the algorithm\n",
    "# test is a list of indices from data to be used for testing\n",
    "# validation is a list of indices from data to be used for validation\n",
    "# train is a list of indices from data to be used for training\n",
    "# features is a list of the indicies for the features to be used to measure distance\n",
    "# target_class is the index of the target class feature\n",
    "# parent node is the parent of the node wanting to be created\n",
    "# feature_element is the element being tested on with this node\n",
    "# feature_quality indicates if the split_feature of the parent node is categorical or continous\n",
    "# returns a list of classes, the indices which correspond to the indices of test\n",
    "# returns a decision tree\n",
    "def id3(data, test, validation, train, features, target_class, parent_node, feature_element, target_type, feature_quality):\n",
    "    # base case, if all train records have the same target class, or only 1 record\n",
    "    base_record_class = data.iloc[train[0],target_class]\n",
    "    check = 0\n",
    "    while(check == 0):\n",
    "        for index in range(len(train)):\n",
    "            # get class of record\n",
    "            record_class = data.iloc[(train[index]),target_class]\n",
    "            # check if it's a different class\n",
    "            if(record_class != base_record_class):\n",
    "                check = 1\n",
    "            # end if\n",
    "        #end for\n",
    "        if(check == 0):\n",
    "            # all target classes were the same\n",
    "            leaf = treeNode( None, feature_element, parent_node, None, True, base_record_class, feature_quality)\n",
    "            return leaf\n",
    "        # end if\n",
    "    # end while           \n",
    "    # second base case, feature set is empty\n",
    "    if(not features):\n",
    "        leaf = treeNode(None, feature_element, parent_node, None, True, base_record_class, feature_quality)\n",
    "        return leaf\n",
    "    # end if\n",
    "    # calculate on which feature we should split\n",
    "    feature_gain_ratios = []\n",
    "    # get gain ratio for each feature\n",
    "    for feature_index in range(len(features)):\n",
    "        feature_gain_ratios.append(gain_ratio(data, train, target_class, features[feature_index]))\n",
    "    # end for\n",
    "    # determine best feature to split on\n",
    "    split_feature = -1\n",
    "    best_gain = -10000000\n",
    "    for index in range(len(feature_gain_ratios)):\n",
    "        if(feature_gain_ratios[index] > best_gain):\n",
    "            best_gain = feature_gain_ratios[index]\n",
    "            split_feature = features[index]\n",
    "        # end if\n",
    "    # end for\n",
    "    #calculate class for interior node, max of target class\n",
    "    unique_classes = []\n",
    "    class_count = []\n",
    "    for index in range(len(train)):\n",
    "        # get record\n",
    "        record = data.iloc[[train[index]]]\n",
    "        # get class\n",
    "        record_class = record.iloc[0,target_class]\n",
    "        # check if class is already in unique_classes list\n",
    "        if(record_class in unique_classes):\n",
    "            # get index of record_class in unique_classes\n",
    "            class_index = unique_classes.index(record_class)\n",
    "            # add count to class_count list in corresponding index\n",
    "            class_count[class_index] = class_count[class_index] + 1\n",
    "        # end if\n",
    "        else: # first instance of this class\n",
    "            unique_classes.append(record_class)\n",
    "            # get index of record_class in unique_classes\n",
    "            class_index = unique_classes.index(record_class)\n",
    "            # add count to class_count list in corresponding index\n",
    "            class_count.append(1)\n",
    "        # end else\n",
    "    # end for\n",
    "    # end else\n",
    "    #get class with highest count\n",
    "    node_class = unique_classes[class_count.index(max(class_count))]\n",
    "    # create base node to use as parent for children\n",
    "    node = treeNode(split_feature,feature_element, parent_node, None, False, node_class, feature_quality)\n",
    "    \n",
    "    \n",
    "    # get child nodes\n",
    "    # determine if split_feature is of object type\n",
    "    colname = data.columns[split_feature]\n",
    "    if(data[colname].dtype == 'O'):\n",
    "        \n",
    "        new_features = copy.deepcopy(features)\n",
    "        new_features.remove(split_feature)\n",
    "        child_nodes = []\n",
    "        unique_elements = []\n",
    "        for index in range(len(train)):\n",
    "            # get record\n",
    "            record = data.iloc[[train[index]]]\n",
    "            # get element\n",
    "            record_element = record.iloc[0,split_feature]\n",
    "            # check if element is already in unique_elements list\n",
    "            if(record_element in unique_elements):\n",
    "                # get index of record_element in unique_elements\n",
    "                element_index = unique_elements.index(record_element)\n",
    "            # end if\n",
    "            else: # first instance of this element\n",
    "                unique_elements.append(record_element)\n",
    "                # get index of unique_classes in unique_elements\n",
    "                element_index = unique_elements.index(record_element)\n",
    "            # end else\n",
    "        # end for\n",
    "        # create a child node for each unique element\n",
    "        for element in range(len(unique_elements)):\n",
    "            child_train = []\n",
    "            child_features = copy.deepcopy(new_features)\n",
    "            for index in range(len(train)):\n",
    "                # get record\n",
    "                record = data.iloc[[train[index]]]\n",
    "                # see if record has value element\n",
    "                record_element = record.iloc[0,split_feature]\n",
    "                if(record_element == unique_elements[element]):\n",
    "                    child_train.append(train[index])\n",
    "                # end if\n",
    "            # end for\n",
    "            child_nodes.append(id3(data, test, validation, child_train, child_features, target_class, node, unique_elements[element], target_type, None))\n",
    "        # end for\n",
    "        node.children = child_nodes\n",
    "    else:\n",
    "        new_features = copy.deepcopy(features)\n",
    "        new_features.remove(split_feature)\n",
    "        child_nodes = []\n",
    "        mean = data[colname].mean()\n",
    "        \n",
    "        child_train1 = []\n",
    "        child_train2 = []\n",
    "        child_features = copy.deepcopy(new_features)\n",
    "        for index in range(len(train)):\n",
    "            # get record\n",
    "            record = data.iloc[[train[index]]]\n",
    "            # see if record has value element\n",
    "            record_element = record.iloc[0,split_feature]\n",
    "            if(record_element >= mean):\n",
    "                child_train1.append(train[index])\n",
    "            # end if\n",
    "            else:\n",
    "                child_train2.append(train[index])\n",
    "            # end else\n",
    "        # end for\n",
    "        if(len(child_train1)>0):\n",
    "            child_nodes.append(id3(data, test, validation, child_train1, child_features, target_class, node, mean, target_type, 1))\n",
    "        # end if\n",
    "        if(len(child_train2)>0):\n",
    "            child_nodes.append(id3(data, test, validation, child_train2, child_features, target_class, node, mean, target_type, -1))\n",
    "        # end if\n",
    "        node.children = child_nodes\n",
    "    # end else\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class treeNode:\n",
    "    \n",
    "    # initializer\n",
    "    def __init__(self, split_feature, feature_element, parent, children, is_leaf, leaf_class, feature_quality):\n",
    "        self.split_feature = split_feature # index of feature on data\n",
    "        self.feature_element = feature_element # element of parent node feature this split is on\n",
    "        self.parent = parent\n",
    "        self.children = children\n",
    "        self.is_leaf = is_leaf\n",
    "        self.leaf_class = leaf_class # element of target class to assign\n",
    "        self.feature_quality = feature_quality # if feature element is the mean of a continous feature, quality indicates if you split on greater than or equal to, or less than"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to print the tree\n",
    "# tree_node is the root of the tree to be printed\n",
    "# prints to the console, nothing is returned\n",
    "def print_tree(tree_node):\n",
    "    print(\"tree node split feature\")\n",
    "    print(tree_node.split_feature)\n",
    "    print(\"tree node feature element\")\n",
    "    print(tree_node.feature_element)\n",
    "\n",
    "    if(tree_node.is_leaf != True):\n",
    "        print(\"children:\")\n",
    "        child_nodes = tree_node.children\n",
    "        for item in child_nodes:\n",
    "            print_tree(item)\n",
    "        # end for\n",
    "        print(\"end children for node\")\n",
    "    # end if\n",
    "    else:\n",
    "        print(\"leaf class:\")\n",
    "        print(tree_node.leaf_class)\n",
    "    # end else\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to calculate the entropy\n",
    "# data is the dataset to be used for the algorithm\n",
    "# train is a list of indices from data to be used for training\n",
    "# target_class is the index of the target class feature\n",
    "# returns the entropy of the data for the training set passed\n",
    "def entropy(data, train, target_class):\n",
    "    total_count = len(train)\n",
    "    unique_classes = []\n",
    "    class_count = []\n",
    "    for index in range(total_count):\n",
    "        # get record\n",
    "        record = data.iloc[[train[index]]]\n",
    "        # get class\n",
    "        record_class = record.iloc[0,target_class]\n",
    "        # check if class is already in unique_classes list\n",
    "        if(record_class in unique_classes):\n",
    "            # get index of record_class in unique_classes\n",
    "            class_index = unique_classes.index(record_class)\n",
    "            # add count to class_count list in corresponding index\n",
    "            class_count[class_index] = class_count[class_index] + 1\n",
    "        # end if\n",
    "        else: # first instance of this class\n",
    "            unique_classes.append(record_class)\n",
    "            # get index of record_class in unique_classes\n",
    "            class_index = unique_classes.index(record_class)\n",
    "            # add count to class_count list in corresponding index\n",
    "            class_count.append(1)\n",
    "        # end else\n",
    "    # end for\n",
    "    entropy = 0\n",
    "    for class_index in range(len(unique_classes)):\n",
    "        entropy = entropy - ((class_count[class_index]/total_count)*math.log((class_count[class_index]/total_count),2))\n",
    "    # end for\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to calculate the expected entropy\n",
    "# data is the dataset to be used for the algorithm\n",
    "# train is a list of indices from data to be used for training\n",
    "# target_class is the index of the target class feature\n",
    "# feature is the index of the feature being tested for\n",
    "# returns the expected entropy of a feature for the training set passed\n",
    "def expected_entropy(data, train, target_class, feature):\n",
    "    total_count = len(train)\n",
    "    feature_elements = []\n",
    "    element_counts = []\n",
    "    element_indices = []\n",
    "    colname = data.columns[feature]\n",
    "    if(data[colname].dtype == 'O'):\n",
    "        for index in range(total_count):\n",
    "            # get record\n",
    "            record = data.iloc[[train[index]]]\n",
    "            # get element\n",
    "            record_element = record.iloc[0,feature]\n",
    "            # check if element is already in feature_elements list\n",
    "            if(record_element in feature_elements):\n",
    "                # get index of record_class in feature_elements\n",
    "                element_index = feature_elements.index(record_element)\n",
    "                # add count to element_counts list in corresponding index\n",
    "                element_counts[element_index] = element_counts[element_index] + 1\n",
    "                # add index of record to element_indices\n",
    "                element_indices[element_index].append(index)\n",
    "            # end if\n",
    "            else: # first instance of this element\n",
    "                feature_elements.append(record_element)\n",
    "                # get index of record_element in feature_elements\n",
    "                element_index = feature_elements.index(record_element)\n",
    "                # add count to class_count list in corresponding index\n",
    "                element_counts.append(1)\n",
    "                # add index of record to element_indices\n",
    "                element_indices.append([index])\n",
    "            # end else      \n",
    "        # end for\n",
    "    # end if\n",
    "    else:\n",
    "        element_counts = [0,0]\n",
    "        element_indices = [[],[]]\n",
    "        for index in range(total_count):\n",
    "            # get mean\n",
    "            mean = data[colname].mean()\n",
    "            # get record\n",
    "            record = data.iloc[[train[index]]]\n",
    "            # get element\n",
    "            record_element = record.iloc[0,feature]\n",
    "            if(record_element >= mean):\n",
    "                # get index of record_class in feature_elements\n",
    "                element_index = 0\n",
    "                # add count to element_counts list in corresponding index\n",
    "                element_counts[element_index] = element_counts[element_index] + 1\n",
    "                # add index of record to element_indices\n",
    "                element_indices[element_index].append(index)\n",
    "            # end if\n",
    "            else: \n",
    "                # get index of record_element in feature_elements\n",
    "                element_index = 1\n",
    "                # add count to class_count list in corresponding index\n",
    "                element_counts[element_index] = element_counts[element_index] + 1\n",
    "                # add index of record to element_indices\n",
    "                element_indices[element_index].append(index)\n",
    "            # end else    \n",
    "        # end for\n",
    "    # end else\n",
    "    expected_entropy = 0\n",
    "    for element_index in range(len(feature_elements)):\n",
    "        expected_entropy = expected_entropy + ((element_counts[element_index]/total_count)*entropy(data, element_indices[element_index],target_class))\n",
    "    # end for\n",
    "    return expected_entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to calcluate the gain ratio\n",
    "# data is the dataset to be used for the algorithm\n",
    "# train is a list of indices from data to be used for training\n",
    "# target_class is the index of the target class feature\n",
    "# feature is the index of the feature being calculated for\n",
    "# returns the gain ratio of a feature for the training set passed\n",
    "def gain_ratio(data, train, target_class, feature):\n",
    "    gain_ratio = (entropy(data, train, target_class) - expected_entropy(data, train, target_class, feature)) / (info_value(data, train, target_class, feature)+0.00001)\n",
    "    return gain_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to calcluate the info value\n",
    "# data is the dataset to be used for the algorithm\n",
    "# train is a list of indices from data to be used for training\n",
    "# target_class is the index of the target class feature\n",
    "# feature is the index of the feature being calculated for\n",
    "# returns the info value of a feature for the training set passed\n",
    "def info_value(data, train, target_class, feature):\n",
    "    total_count = len(train)\n",
    "    feature_elements = []\n",
    "    element_counts = []\n",
    "    colname = data.columns[feature]\n",
    "    if(data[colname].dtype == 'O'):\n",
    "        for index in range(total_count):\n",
    "            # get record\n",
    "            record = data.iloc[[train[index]]]\n",
    "            # get element\n",
    "            record_element = record.iloc[0,feature]\n",
    "            # check if element is already in feature_elements list\n",
    "            if(record_element in feature_elements):\n",
    "                # get index of record_class in feature_elements\n",
    "                element_index = feature_elements.index(record_element)\n",
    "                # add count to element_counts list in corresponding index\n",
    "                element_counts[element_index] = element_counts[element_index] + 1\n",
    "            # end if\n",
    "            else: # first instance of this element\n",
    "                feature_elements.append(record_element)\n",
    "                # get index of record_element in feature_elements\n",
    "                element_index = feature_elements.index(record_element)\n",
    "                # add count to class_count list in corresponding index\n",
    "                element_counts.append(1)\n",
    "            # end else      \n",
    "        # end for\n",
    "    # end if\n",
    "    else:\n",
    "        element_counts = [0,0]\n",
    "        for index in range(total_count):\n",
    "            # get mean\n",
    "            mean = data[colname].mean()\n",
    "            # get record\n",
    "            record = data.iloc[[train[index]]]\n",
    "            # get element\n",
    "            record_element = record.iloc[0,feature]\n",
    "            if(record_element >= mean):\n",
    "                # get index of record_class in feature_elements\n",
    "                element_index = 0\n",
    "                # add count to element_counts list in corresponding index\n",
    "                element_counts[element_index] = element_counts[element_index] + 1\n",
    "            # end if\n",
    "            else: \n",
    "                # get index of record_element in feature_elements\n",
    "                element_index = 1\n",
    "                # add count to class_count list in corresponding index\n",
    "                element_counts[element_index] = element_counts[element_index] + 1\n",
    "            # end else    \n",
    "        # end for\n",
    "    # end else\n",
    "    info_value = 0\n",
    "    for element_index in range(len(feature_elements)):\n",
    "        info_value = info_value - ((element_counts[element_index]/total_count)*math.log((element_counts[element_index]/total_count),2))\n",
    "    # end for\n",
    "    return info_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance\n",
    "# data is the dataset to be used for the algorithm\n",
    "# test is a list of indices from data to be used for testing\n",
    "# test_classes is a list with the class for the test dataset that includes the estimate for the target_class\n",
    "# features is a list of the indicies for the features to be used to measure distance\n",
    "# target_class is the index of the target class feature\n",
    "# returns the performance of the data passed\n",
    "def performance(data, test, test_classes, target_class, target_type):\n",
    "    n_data = len(test) # this is the number of records to be tested\n",
    "    curr_perf = 0\n",
    "    # classification error\n",
    "    for record in range(n_data): # record is index in test \n",
    "        test_record = data.iloc[[test[record]]] # pulls record to test\n",
    "        if(test_record.iloc[0,target_class] != test_classes[record]):\n",
    "            curr_perf = curr_perf + 1\n",
    "        # end if\n",
    "    # end for\n",
    "    curr_perf = curr_perf / n_data\n",
    "    return curr_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Pruning\"></a>\n",
    "## Reduced Error Pruning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to create a pruned decision tree and test it on a set of test data\n",
    "# data is the dataset to be used for the algorithm\n",
    "# test is a list of indices from data to be used for testing\n",
    "# validation is a list of indices from data to be used for validation\n",
    "# train is a list of indices from data to be used for training\n",
    "# features is a list of the indicies for the features to be used to measure distance\n",
    "# target_class is the index of the target class feature\n",
    "# returns a list of classes, the indices which correspond to the indices of test\n",
    "def test_id3_pruned(data, test, validation, train, features, target_class, target_type):\n",
    "    #initialize non-pruned tree as best tree and get error\n",
    "    best_tree = id3(data, test, validation, train, features, target_class, None, None, target_type, None)\n",
    "    best_perf = test_tree(best_tree, data, validation, train, features, target_class, target_type) # this will be error, so looking to minimize error\n",
    "    \n",
    "    # prune tree from leaf up, keep tree if beats performance\n",
    "    check = 0\n",
    "    new_tree = copy.deepcopy(best_tree)\n",
    "    while(check == 0):\n",
    "        node = new_tree\n",
    "        while(not node.is_leaf):\n",
    "            children = node.children\n",
    "            for child_node in children:\n",
    "                node = child_node\n",
    "                if(children is not None):\n",
    "                    children = children.remove(child_node)\n",
    "                # end if\n",
    "            # end for\n",
    "            if(node.split_feature == None):\n",
    "                node.is_leaf = True\n",
    "            # end if\n",
    "        # end while // node should be a leaf now\n",
    "        node = node.parent\n",
    "        node.is_leaf = True\n",
    "        perf = test_tree(new_tree, data, validation, train, features, target_class, target_type)\n",
    "        if(perf < best_perf):\n",
    "            best_tree = new_tree\n",
    "            best_perf = perf\n",
    "        # end if\n",
    "        else:\n",
    "            check = 1\n",
    "        # end else\n",
    "    # end while\n",
    "    \n",
    "    # use final tree to get classes for validation dataset\n",
    "    test_classes = []\n",
    "    for index in range(len(test)):\n",
    "        # get record\n",
    "        node = best_tree\n",
    "        node_feature = node.split_feature # index of feature in data being tested for\n",
    "        record = data.iloc[[test[index]]]\n",
    "        check = 0\n",
    "        record_class = -1\n",
    "        while(check == 0):\n",
    "            if(node.is_leaf == True):\n",
    "                record_class = node.leaf_class\n",
    "                check = 1\n",
    "            # end if\n",
    "            if(node_feature == None):\n",
    "                record_class = node.leaf_class\n",
    "                check = 1\n",
    "            # end if\n",
    "            # node is not leaf, move to next level\n",
    "            # cycle through child nodes until find the one we want\n",
    "            if(check == 0):\n",
    "                child_nodes = node.children\n",
    "                check2 = 0\n",
    "                while(check2 == 0):\n",
    "                    for child_node_index in range(len(child_nodes)):\n",
    "                        child_node = child_nodes[child_node_index]\n",
    "                        # check if node is split on an object feature\n",
    "                        colname = data.columns[node_feature]\n",
    "                        if(child_node.feature_quality == None or data[colname].dtype == 'O'):\n",
    "                            if(child_node.feature_element == record.iloc[0,node_feature]):\n",
    "                                # this is our child node, update accordingly\n",
    "                                node = child_node\n",
    "                                check2 = 1\n",
    "                                if(child_node.split_feature == None):\n",
    "                                    node_feature = target_class\n",
    "                                # end if\n",
    "                                else:\n",
    "                                    node_feature = child_node.split_feature\n",
    "                                # end else  \n",
    "                            # end if  \n",
    "                        # end if\n",
    "                        else:\n",
    "                            if(child_node.feature_quality > 0 and record.iloc[0,node_feature] >= child_node.feature_element): \n",
    "                                # this is our child node, update accordingly\n",
    "                                node = child_node\n",
    "                                if(child_node.split_feature == None):\n",
    "                                    node_feature = target_class\n",
    "                                # end if\n",
    "                                else:\n",
    "                                    node_feature = child_node.split_feature\n",
    "                                # end else\n",
    "                                check2 = 1\n",
    "                            # end if  \n",
    "                            else:\n",
    "                                if(child_node.feature_quality < 0 and record.iloc[0,node_feature] < child_node.feature_element):\n",
    "                                    # this is our child node, update accordingly\n",
    "                                    node = child_node\n",
    "                                    if(child_node.split_feature == None):\n",
    "                                        node_feature = target_class\n",
    "                                    # end if\n",
    "                                    else:\n",
    "                                        node_feature = child_node.split_feature\n",
    "                                    # end else\n",
    "                                    check2 = 1\n",
    "                                # end if\n",
    "                            # end else\n",
    "                        # end else\n",
    "                        \n",
    "                    # end for\n",
    "                    if(check2 == 0): # cycled through all child nodes, none of the features matched, return class of node\n",
    "                        record_class = node.leaf_class\n",
    "                        check2 = 1\n",
    "                        check = 1\n",
    "                    # end if\n",
    "                # end while               \n",
    "            # end if\n",
    "        # end while\n",
    "        test_classes.append(record_class)\n",
    "    #end for\n",
    "    best_perf = performance(data, validation, test_classes, target_class, target_type) \n",
    "\n",
    "    return test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to test the performance of a tree\n",
    "# tree is the root of the tree to be tested\n",
    "# data is the dataset to be used for the algorithm\n",
    "# test is a list of indices from data to be used for testing\n",
    "# validation is a list of indices from data to be used for validation\n",
    "# train is a list of indices from data to be used for training\n",
    "# features is a list of the indicies for the features to be used to measure distance\n",
    "# target_class is the index of the target class feature\n",
    "# returns the performance of the tree on the validation set\n",
    "def test_tree(tree, data, validation, train, features, target_class, target_type):\n",
    "    # use tree to get classes for validation dataset\n",
    "    validation_classes = []\n",
    "    for index in range(len(validation)):\n",
    "        # get record\n",
    "        node = tree\n",
    "        node_feature = node.split_feature # index of feature in data being tested for\n",
    "        record = data.iloc[[validation[index]]]\n",
    "        check = 0\n",
    "        record_class = -1\n",
    "        while(check == 0):\n",
    "            if(node.is_leaf == True):\n",
    "                record_class = node.leaf_class\n",
    "                check = 1\n",
    "            # end if\n",
    "            if(node_feature == None):\n",
    "                record_class = node.leaf_class\n",
    "                check = 1\n",
    "            # end if\n",
    "            # node is not leaf, move to next level\n",
    "            # cycle through child nodes until find the one we want\n",
    "            if(check == 0):\n",
    "                child_nodes = node.children\n",
    "                check2 = 0\n",
    "                while(check2 == 0):\n",
    "                    for child_node_index in range(len(child_nodes)):\n",
    "                        child_node = child_nodes[child_node_index]\n",
    "                        # check if node is split on an object feature\n",
    "                        colname = data.columns[node_feature]\n",
    "                        if(child_node.feature_quality == None or data[colname].dtype == 'O'):\n",
    "                            if(child_node.feature_element == record.iloc[0,node_feature]):\n",
    "                                # this is our child node, update accordingly\n",
    "                                node = child_node\n",
    "                                check2 = 1\n",
    "                                if(child_node.split_feature == None):\n",
    "                                    node_feature = target_class\n",
    "                                # end if\n",
    "                                else:\n",
    "                                    node_feature = child_node.split_feature\n",
    "                                # end else  \n",
    "                            # end if  \n",
    "                        # end if\n",
    "                        else:\n",
    "                            if(child_node.feature_quality > 0 and record.iloc[0,node_feature] >= child_node.feature_element): \n",
    "                                # this is our child node, update accordingly\n",
    "                                node = child_node\n",
    "                                if(child_node.split_feature == None):\n",
    "                                    node_feature = target_class\n",
    "                                # end if\n",
    "                                else:\n",
    "                                    node_feature = child_node.split_feature\n",
    "                                # end else\n",
    "                                check2 = 1\n",
    "                            # end if  \n",
    "                            else:\n",
    "                                if(child_node.feature_quality < 0 and record.iloc[0,node_feature] < child_node.feature_element):\n",
    "                                    # this is our child node, update accordingly\n",
    "                                    node = child_node\n",
    "                                    if(child_node.split_feature == None):\n",
    "                                        node_feature = target_class\n",
    "                                    # end if\n",
    "                                    else:\n",
    "                                        node_feature = child_node.split_feature\n",
    "                                    # end else\n",
    "                                    check2 = 1\n",
    "                                # end if\n",
    "                            # end else\n",
    "                        # end else\n",
    "                        \n",
    "                    # end for\n",
    "                    if(check2 == 0): # cycled through all child nodes, none of the features matched, return class of node\n",
    "                        record_class = node.leaf_class\n",
    "                        check2 = 1\n",
    "                        check = 1\n",
    "                    # end if\n",
    "                # end while               \n",
    "            # end if\n",
    "        # end while\n",
    "        validation_classes.append(record_class)\n",
    "    #end for\n",
    "    perf = performance(data, validation, validation_classes, target_class, target_type) \n",
    "    return perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Processing\"></a>\n",
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_features = [0,1,2,3,4,5,6,7]\n",
    "# 10-fold+validation split\n",
    "n=11\n",
    "list_of_indices = list(range(len(abalone)))\n",
    "n_data = len(abalone) #this is the number of records in the data\n",
    "test_size = int(n_data/n) #this is the number of records in each test set\n",
    "df = abalone.sample(frac=1).reset_index(drop=True) # a dataframe with shuffled records\n",
    "df.sort_values(by= df.columns[8]) # sorts the data by the target class\n",
    "splits = []    \n",
    "# create n splits \n",
    "for i in range(n):\n",
    "    split = []\n",
    "    splits.append(split)\n",
    "# end for\n",
    "# splitting the folds so that each fold has approx. the same number of each class\n",
    "counter = 0\n",
    "for count in range(test_size):\n",
    "    for i in range(n):\n",
    "        splits[i].append(n*count +counter)\n",
    "        counter = counter +1\n",
    "    # end for\n",
    "    counter = 0\n",
    "# end for\n",
    "\n",
    "test_split = splits[0]\n",
    "validation_split = splits[1]\n",
    "train_split = []\n",
    "for index in range(n_data):\n",
    "    if(index not in test_split and index not in validation_split):\n",
    "        train_split.append(index)\n",
    "    # end if\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run algorithm\n",
    "test_classes = test_id3(df, test_split, validation_split, train_split, abalone_features, 8, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8891820580474934\n"
     ]
    }
   ],
   "source": [
    "output = performance(df, test_split, test_classes, 8, 2) \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run algorithm\n",
    "test_classes2 = test_id3_pruned(df, test_split, validation_split, train_split, abalone_features, 8, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8179419525065963\n"
     ]
    }
   ],
   "source": [
    "output2 = performance(df, test_split, test_classes2, 8, 2) \n",
    "print(output2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
