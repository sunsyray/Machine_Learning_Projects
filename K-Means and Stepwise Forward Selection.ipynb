{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code performs 2 algorithms, k-Means Clustering and Stepwise Forward Selection, on the Iris dataset from the UCI Machine Learning Repository https://archive.ics.uci.edu/ml/index.php\n",
    "\n",
    "[Datasets](#Datasets):   \n",
    "[Iris](#Iris)- 3 classes    \n",
    "  \n",
    "Clustering Algorithm:  \n",
    "[k-Means](#k_means)   \n",
    "\n",
    "Feature Selection Algorithm:  \n",
    "[SFS](#SFS)    \n",
    "\n",
    "[Models](#Models)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Datasets\"></a>\n",
    "# Datasets\n",
    "\n",
    "<a id=\"Iris\"></a>\n",
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"iris.data\", header=None, names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width','iris_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal_length    150 non-null float64\n",
      "sepal_width     150 non-null float64\n",
      "petal_length    150 non-null float64\n",
      "petal_width     150 non-null float64\n",
      "iris_class      150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"k_means\"></a>\n",
    "## k-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Means is a unsupervised ML algorithm (no class labels are required to create the model) \n",
    "#         that identifies k clusters in the data\n",
    "# The assumption for k-Means is that the underlying classes come from k Gaussian Distributions\n",
    "\n",
    "# requires k > 0, data contains at least k records\n",
    "# data is the full dataset\n",
    "# features is a list with the index of each feature being used in the algorithm\n",
    "# k is the number of clusters\n",
    "# returns centroids and model_output\n",
    "def k_means(data, features, k):\n",
    "    np.random.seed(619884949)\n",
    "    centroids = [] # centroids lists the k centroids\n",
    "    n = len(data.index) # num of records in the data\n",
    "    # initialize the random k centroids to start\n",
    "    for index in range(k):\n",
    "        # pull random record to use as initial starting point\n",
    "        record_index = random.randint(1,n-1)\n",
    "        random_record = data.iloc[[record_index]]\n",
    "#        print(random_record)\n",
    "        centroid = []\n",
    "        for feature in features:\n",
    "            centroid.append(random_record.iloc[0,feature])\n",
    "        # end for\n",
    "        centroids.append(centroid)\n",
    "#        print(centroid)\n",
    "    # end for\n",
    "    # model_output is an array with n records, where the index matches the index of the records in the data, and the \n",
    "    # value matches the centroid associated with that record\n",
    "    model_output = []\n",
    "    convergence = 0\n",
    "    cycles = 0\n",
    "    while(convergence == 0):\n",
    "        # update model_output with data based on current centroids\n",
    "        model_output = calc_clusters(data, features, centroids)\n",
    "#        print(centroids)\n",
    "#        print(model_output)\n",
    "        # recalculate centroids\n",
    "        centroids, changes = calc_centroids(data, model_output, centroids, features)\n",
    "        if(changes == 0):\n",
    "            # no change to centroids leave while loop\n",
    "            convergence = 1\n",
    "        # end if\n",
    "        cycles = cycles + 1\n",
    "        if(cycles > 100):\n",
    "            print('More than 100 cycles, timed out.')\n",
    "            convergence = 1\n",
    "        # end if\n",
    "    # end while\n",
    "    return centroids, model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is the full dataset\n",
    "# features is a list with the index of each feature being used in the algorithm\n",
    "# centroids is the current list of centroids\n",
    "# returns model_output a list with n records, where the index matches the index of the records in the data, and the \n",
    "#      value matches the centroid associated with that record\n",
    "def calc_clusters(data, features, centroids):\n",
    "    model_output = []\n",
    "    n = len(data.index) # num records in data\n",
    "    # loop through all records\n",
    "    for index in range(n):\n",
    "        curr_record = data.iloc[[index]]\n",
    "        shortest = 1000000000000 # default to very large number\n",
    "        cluster = -1 # tracks the cluster for this record\n",
    "        cluster_num = 0 # count to track which centroid we are testing for\n",
    "        # loop through each centroid\n",
    "        for centroid in centroids: # centroid is list of current means for each cluster\n",
    "            # calc distance\n",
    "            dist = distance(centroid, curr_record, features)\n",
    "            if(dist < shortest): # if dist is less than shortest, this is the closest centroid so far\n",
    "                cluster = cluster_num # assign this record to this centroid\n",
    "                shortest = dist # assign new distance as closest\n",
    "            # end if\n",
    "            cluster_num = cluster_num + 1 # moving to next centroid\n",
    "        # end for\n",
    "        # after looping through all centroids, update the model_output with this index's assigned centroid\n",
    "        model_output.append(cluster)\n",
    "    # end for   \n",
    "    \n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is the full dataset\n",
    "# model_output a list with n records, where the index matches the index of the records in the data, and the \n",
    "#      value matches the centroid associated with that record\n",
    "# centroids is the current list of centroids\n",
    "# features is a list with the index of each feature being used in the algorithm\n",
    "# returns new_centroids, which is the updated list of centroids, and changes which is the number of changes to the \n",
    "#        list of centroids provided to the function\n",
    "def calc_centroids(data, model_output, centroids, features):\n",
    "    new_centroids = [] # updates with new centroids based on model_output provided\n",
    "    changes = 0 # tracks the changes to the centroids\n",
    "#    print(centroids)\n",
    "#    print(model_output)\n",
    "    n = len(data.index) # num of records in the data\n",
    "    num_features = len(features) # num of features\n",
    "    centroid_number = 0 # tracks the centroid number being calculated\n",
    "    for centroid in centroids: # centroid is the list of means\n",
    "        new_centroid = [] # updates with new calculated means for this centroid\n",
    "        for index in range(num_features): # index cycles through all features, the index of each feature, not the feature index\n",
    "            new_feature_mean = 0 # tracks the calculation for the new mean\n",
    "            records_in_centroid = 0.0001 # tracks the number of records for this centroid in the model_output. very small number in case there ends up with 0 records, no dividing by 0\n",
    "            # loope through all records\n",
    "            for record in range(n):\n",
    "                curr_record = data.iloc[[record]]\n",
    "                if(model_output[record]  == centroid_number): # if the model_output index for this record matches the current centroid being calculated\n",
    "                    records_in_centroid = records_in_centroid + 1 # update the number of records for this centroid\n",
    "                    new_feature_mean = new_feature_mean + curr_record.iloc[0,features[index]] # add the value of the feature for this record\n",
    "                # end if\n",
    "            # end for\n",
    "            new_feature_mean = new_feature_mean / records_in_centroid # divide the total value of that feature for this centroid and divide by number of records\n",
    "            new_centroid.append(new_feature_mean) # add new mean to this centroid\n",
    "        # end for\n",
    "        new_centroids.append(new_centroid) # add new centroid to the list of centroids\n",
    "        # count how many of the centroids changed\n",
    "        for count in range(num_features):\n",
    "            if(centroid[count] != new_centroid[count]):\n",
    "                changes = changes +1\n",
    "            # end if\n",
    "        # end for\n",
    "        centroid_number = centroid_number + 1\n",
    "    # end for\n",
    "    return new_centroids, changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid is the centroid to calculate the distance to\n",
    "# record is the instance to calculate the distance from\n",
    "# features is a list with the index of each feature being used in the algorithm\n",
    "# returns dist which is the distance from the centroid to the record\n",
    "def distance(centroid, record, features):\n",
    "    dist = 0\n",
    "    # centroid is a list with the means for each feature\n",
    "    # calculate distance between centroid and record\n",
    "    count = 0 # keeps track of which # feature we are on\n",
    "    for feature in features:\n",
    "        dist = dist + (record.iloc[0,feature] - centroid[count])**2 # sum up all the squares\n",
    "        count = count + 1\n",
    "    # end for\n",
    "    dist = np.sqrt(dist) # take the square root of the sum of squares\n",
    "        \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SFS\"></a>\n",
    "## SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepwise Forward Selection is a feature selection algorithm that begins by choosing one feature with the best performance,\n",
    "# then adds a new feature if the performance is better than the prior best performance, on until there is no further\n",
    "# improvement, at which point it returns that best performing list of features.\n",
    "\n",
    "# Since this is a wrapper algorithm, this particular version utlizes the k-Means clustering algorithm above.\n",
    "\n",
    "# features is a list with the index of all features being used in the algorithm \n",
    "# data is the full dataset\n",
    "# k is the number of clusters\n",
    "# returns f_0 which is the final selected list of features which has the best performance based on the SFS algorithm\n",
    "def SFS(features, data, k):\n",
    "    \n",
    "    f_0 = [] # working feature set\n",
    "    base_perf = -1000000 ## set to very small number\n",
    "    f = features\n",
    "    \n",
    "    while(len(f) > 0):\n",
    "        best_perf = -1000000 ## set to very small number-*\n",
    "        best_F = 1\n",
    "        # loop through all features\n",
    "        for feature in f: # feature is the index of the current feature\n",
    "            if(f_0 is None):\n",
    "                f_0 = []\n",
    "            # end if\n",
    "            f_0.append(feature) # add current feature to working feature set\n",
    "            print(\"new f being tested\")\n",
    "            print(f_0)\n",
    "            centroids, model_output = k_means(data, f_0, k) # train new model_output with current feature set\n",
    "            print(centroids)\n",
    "            print(model_output)\n",
    "            curr_perf = Perf(centroids, model_output, data, f_0) # determine the performance of the model\n",
    "            print(curr_perf)\n",
    "            if(curr_perf > best_perf): # if the current feature added increases the performance\n",
    "                best_perf = curr_perf # update best_perf \n",
    "                best_F = feature \n",
    "            # end if\n",
    "            f_0.remove(feature) # remove the feature from the current feature set\n",
    "        # end for\n",
    "        print(best_perf)\n",
    "        print(best_F)\n",
    "        print(base_perf)\n",
    "        if(best_perf > base_perf): # check to see if the feature set created is better than the base\n",
    "            print(\"best was better than base\")\n",
    "            print(f)\n",
    "            print(best_F)\n",
    "            base_perf = best_perf\n",
    "            if(f_0 is None):\n",
    "                f_0 = []\n",
    "            # end if\n",
    "            f_0.append(best_F)\n",
    "            f.remove(best_F)\n",
    "        # end if\n",
    "        else:\n",
    "            f = [] # empty F so it ends the while loop, the best F remaining isn't good enough to add to our feature set\n",
    "        # end else\n",
    "    # end while\n",
    "    return f_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines the performance of the model based on the Silhouette Coefficient\n",
    "\n",
    "\n",
    "# centroids is the current list of centroids\n",
    "# model_output a list with n records, where the index matches the index of the records in the data, and the \n",
    "#      value matches the centroid associated with that record\n",
    "# data is the full dataset\n",
    "# features is a list with the index of features being used\n",
    "def Perf(centroids, model_output, data, features):\n",
    "    final_perf = 0 # this will be the sum of all the coefficients for the data returned by this method\n",
    "    n = len(data.index) # num records in data\n",
    "    num_centroids = len(centroids) # num centroids (k)\n",
    "    num_features = len(features) # number of features for this model\n",
    "    \n",
    "    # loop through all records to get s_i for each datapoint\n",
    "    for index in range(n):\n",
    "        curr_record = data.iloc[[index]]\n",
    "        # calculate average distance to all other records, adding distance to variables according to centroid\n",
    "        cluster_ci = model_output[index] # class predicted by the model\n",
    "        sum_dist_cj = [0]*num_centroids # tracks the sum of all distances between record_xi and all points in the cluster_cj\n",
    "        mi_points_in_cj = [0.0001]*num_centroids # total points in cluster_cj\n",
    "        ave_dist_bi = 100000000000000 # set to very high number\n",
    "        ave_dist_ai = 0 # default to 0\n",
    "        for index_other in range(n):\n",
    "            if(index_other != index):\n",
    "                other_record = data.iloc[[index_other]]\n",
    "                cluster_other = model_output[index_other]\n",
    "                sum_dist_cj[cluster_other] = sum_dist_cj[cluster_other] + distance_perf(curr_record, other_record, features)\n",
    "                mi_points_in_cj[cluster_other] = mi_points_in_cj[cluster_other] + 1\n",
    "        # end for\n",
    "        for index_centroid in range(num_centroids):\n",
    "            if(index_centroid == cluster_ci):\n",
    "                ave_dist_ai = sum_dist_cj[index_centroid] / mi_points_in_cj[index_centroid]\n",
    "            # end if\n",
    "            else:\n",
    "                temp = sum_dist_cj[index_centroid] / mi_points_in_cj[index_centroid] \n",
    "                if(temp < ave_dist_bi):\n",
    "                    ave_dist_bi = temp\n",
    "                # end if\n",
    "            # end else\n",
    "            \n",
    "        # then calculate the silhouette coefficient for record_xi\n",
    "        s_i = (ave_dist_bi - ave_dist_ai) / max(ave_dist_ai, ave_dist_bi)\n",
    "        final_perf = final_perf + s_i\n",
    "    # end for\n",
    "    # take the average of the silhouette coefficients\n",
    "    final_perf = final_perf / n\n",
    "    # return final performance measure\n",
    "    return final_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_perf(record1, record2, features):\n",
    "    dist = 0\n",
    "    # calculate distance between 2 records\n",
    "    for feature in features: # feature is the index of the current feature\n",
    "        dist = dist + ((record1.iloc[0,feature] - record2.iloc[0,feature])**2 )# sum up all the squares\n",
    "    # end for\n",
    "    dist = np.sqrt(dist) # take the square root of the sum of squares\n",
    "        \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Models\"></a>\n",
    "## Models  \n",
    "\n",
    "First we test the K-means algorithm with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_features = [0,1,2,3]\n",
    "iris_means, iris_model_output = k_means(iris, iris_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.849981973731648, 3.073676121904941, 5.742090152394335, 2.071047181454785], [5.90160338451067, 2.7483826638989295, 4.393541300739837, 1.4338686550505564], [5.005989988020024, 3.4179931640136725, 1.463997072005856, 0.2439995120009759]]\n"
     ]
    }
   ],
   "source": [
    "print(iris_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(iris_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_perf = Perf(iris_means, iris_model_output, iris, iris_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5525919040451229\n"
     ]
    }
   ],
   "source": [
    "print(iris_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we test the SFS algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new f being tested\n",
      "[0]\n",
      "[[5.769800434338803], [6.774496520595054], [4.8956415312140615]]\n",
      "[2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 1, 0, 1, 2, 1, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0]\n",
      "0.561274695778297\n",
      "new f being tested\n",
      "[1]\n",
      "[[2.5851008827640785], [3.638878780892275], [3.068652136340095]]\n",
      "[1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 0, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 1, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 1, 2, 0, 2, 0, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 1, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 1, 2]\n",
      "0.5526076774847333\n",
      "new f being tested\n",
      "[2]\n",
      "[[4.290732794939268], [5.628248634242097], [1.463997072005856]]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "0.6781848172219452\n",
      "new f being tested\n",
      "[3]\n",
      "[[2.0739085349814452], [1.337034561047109], [0.2439995120009759]]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7237786878600426\n",
      "0.7237786878600426\n",
      "3\n",
      "-1000000\n",
      "best was better than base\n",
      "[0, 1, 2, 3]\n",
      "3\n",
      "new f being tested\n",
      "[3, 0]\n",
      "[[1.4629602537773074, 5.892581680404296], [2.011899971666734, 6.857126530651117], [0.3018512928679761, 5.005546286025396]]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "0.5051309579207565\n",
      "new f being tested\n",
      "[3, 1]\n",
      "[[1.6759983240016765, 2.871997128002873], [0.280951043090271, 3.761886848157866], [0.21724063020472348, 3.168954589811759]]\n",
      "[1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.5252223919911053\n",
      "new f being tested\n",
      "[3, 2]\n",
      "[[1.3592567421171438, 4.292584643361772], [2.047821635170358, 5.626074725924507], [0.2439995120009759, 1.463997072005856]]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "0.6600587623826453\n",
      "0.6600587623826453\n",
      "2\n",
      "0.7237786878600426\n"
     ]
    }
   ],
   "source": [
    "iris_base_features = [0,1,2,3]\n",
    "iris_SFS_features = SFS(iris_base_features, iris, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(iris_SFS_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_means, iris_model_output = k_means(iris, iris_SFS_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.058329045147822], [1.3230743787031178], [0.2439995120009759]]\n"
     ]
    }
   ],
   "source": [
    "print(iris_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(iris_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_perf = Perf(iris_means, iris_model_output, iris, iris_SFS_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7259830692470867\n"
     ]
    }
   ],
   "source": [
    "print(iris_perf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
